\documentclass{article}

\begin{document}


<<opts, echo=FALSE>>=
opts_chunk$set(size='footnotesize', fig.align='center', cache=TRUE)
c1_fullv <- readRDS('plot.Rdata')
userStatsFinal <- readRDS('Ustats.Rdata')
@

\section*{Explore Data}
First, I re-collect all the data that has been saved off after each week. Then, I create some summaries and do some data exploration and cleaning.

The dates where tweets were collected are 
\begin{itemize}
  \item 03-05-2014
  \item 03-20-2014
  \item 04-06-2014
\end{itemize}

<<ExploreData, eval=FALSE>>=

collectDates<-c('2014-03-05','2014-03-20','2014-04-06')

#AT_test is the list of Advisor Talk tweets
AT_test <- ldply(collectDates, function(x) {
  res <- readRDS(paste0("AT_", x,".Rdata"))
  res$ext_dt <- x
  res
})

#drop the retweets from the AT_test collection
AT_test_noRT <- subset(AT_test,!isRetweet)


#UH_test is all the tweets for users that participated in an Advisor Talk
UH_test <- ldply(collectDates, function(x) {
  res <- readRDS(paste0("UserHist_", x,".Rdata"))
  res$ext_dt <- x
  res
})
#get user/account details
at_users<-twListToDF(lookupUsers(unique(AT_test_noRT$screenName)))
at_uids<-at_users$id
#de-dup tweets in UH, may have pulled duplicates since history was pulled 3 times
UH_test2<-UH_test[!duplicated(UH_test$id),]

AT_summ<-ddply(AT_test,.(screenName),summarise,
               n_AT_tw = length(id),
               n_AT_ses = length(unique(ext_dt),
               n_AT_RT  = sum(retweetCount))
               )

#general stats on n_following n_followers

userStats<-ddply(UH_test2,.(screenName),summarise,
                min_dt = min(created),
                max_dt = max(created),
                n_tw = length(screenName),
                avg_RT = (sum(retweetCount)/n_tw)
                 )

userStatsFinal<-merge((at_users[,c(13,1:12,14:16)]),merge(userStats,AT_summ, by="screenName"),by="screenName")
userStatsFinal<-userStatsFinal[,c(2,1,3:21)]

#create dataset by day/user to do a line plot

byDay<-ddply(UH_test2,.(screenName,round_date(UH_test2$created,unit = c("day"))),summarise,
      n = length(id))
colnames(byDay)<-c("screenName","day","n")

at_uids3<-userStatsFinal$id[userStatsFinal$n_AT_ses == 3]

@
One of the interesting features in collecting the data was that retweets are returned in the searches. But by default, are not included in the user's history. This can be adjusted in the twitteR function UserTimeline by setting the includeRts option. 

Another issue is rate limiting. I am exploring some ways to pull the data from twitter more effectively. For now, because this is an exploratory project, I am using a smaller subset of data to begin with.

I chose to eliminate retweets from the talk sessions, since the user who re-tweets is not generating their own content.

The derived variables created for each user include 
\begin{itemize}
  \item Number of #Advisor Talk tweets 
   \item Number of #Advisor Talk sessions
  \item Number of retweets of #AdvisorTalk tweets
  \item minimum date of all tweets collected          
  \item maximum date of all tweets collected  
  \item Number of tweets collected in user history
  \item proportion of tweets that are retweeted
\end{itemize}

There are also a number of variables available directly, that may be valuable.
\begin{itemize}
  \item user description
  \item url
  \item name
  \item created
  \item location
  \item profileImageUrl
  \item statuses Count
  \item followers Count
  \item favorites Count
  \item friends Count
\end{itemize}

<<table>>=
head(userStatsFinal)
@



Some terms that will be important throughout the analysis are defined below.
\begin{itemize}
  \item Followers: Users that receive your updates in their feed
  \item Friends: Users that you follow
  \item Favorites: Number of Tweets favorited in account history
\end{itemize}

<<Explore UserHistory,eval=FALSE, echo=FALSE>>=

#created is POSIXct, use round_date from lubridate to get datepart.
qplot(round_date(userStatsFinal$created,unit = c("day")),geom="histogram")

ggplot(aes(x=day,y=n,group=screenName,colour=screenName),data=byDay)+
  geom_line()+xlim(c(ymd("2014-03-03"),ymd("2014-04-07")))

table(userStatsFinal$n_AT_ses)


#only those users that participated in all 3 sessions
ggplot(aes(x=day,y=n,group=screenName,colour=screenName),data=byDay[byDay$screenName %in% users3,])+
  geom_line()+xlim(c(ymd("2014-03-03"),ymd("2014-04-07")))

@
\section*{Social Network Graphs}

In this section I explore network graphs to measure relationships among users. I am currently using friend relationships to create network edges. Replies and Retweets are also good options for describing the connection between users. I am using Sys.sleep to pause my function and avoid some rate limits.

<<Graphing Data, eval=FALSE>>=


# rate limited at 15 calls in 15 minutes
friends_df<-ldply(at_uids3,function(x){
  Sys.sleep(60)
  x1<-getUser(x)$getFriendIDs()
  x2<-x1[x1 %in% at_uids]
  return(data.frame(cbind(node_id = x,friend_id = x2,friend = 1)))
})


library(igraph) 
##############add vertex properties to graph data frame#############
c1_fullv <- graph.data.frame(d = c1, vertices = userStatsFinal) 
get.edge.attribute(c1_fullv, 'friend')

V(c1_fullv) 
#returns a list of the IDs of each vertex in the  graph. 
p1<-plot(c1_fullv)
reports_to_layout <- layout.fruchterman.reingold(c1_fullv)

@
I haven't been able to collect all the data necessary to link all the user nodes. The graph currently shows the relationships of 9 users to other participants of the talk series. 

<<Graphs>>=
plot(c1_fullv, layout=reports_to_layout)
@

\section*{Future Work}

This is primarily an exploratory effort to understand the data that is available via twitter, and the ease of access through R and the twitteR package. There are many potential extensions of this information. 

\begin{itemize}
  \item Search Twitter for tweets regarding retirement, financial services, etc. and then scrape the profile descriptions and urls of those users to see what other web presence those users have. See if we can link twitter handles to linked in profiles, and pull any information from LinkedIn.

\item Try Sentiment Analysis of the tweets collected.

\item Identify what proportion of tweets among these users are 'business' related (retirement, investment, 401k, etc.) vs. personal.
\end{itemize}
\end{document}
